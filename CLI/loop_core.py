"""
æ ¸å¿ƒå¾ªç¯æ¨¡å—
"""

import asyncio
import json
import os
import shlex
import sys
import time
from enum import Enum
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
from display import _print_box, aprint, format_time
from json_utils import (
    JSONBuffer,
    clean_invalid_unicode,
    detect_and_decode,
)
from prompts import (
    JUDGE_SYSTEM,
    REFINE_SYSTEM,
    SUMMARIZE_SYSTEM,
    GOAL_UPDATER_SYSTEM,
)
from token_stats import LoopState, RoundLog, TokenStats


# ------------------------------------------------------------
# çŠ¶æ€æšä¸¾
# ------------------------------------------------------------


class AppStatus(Enum):
    IDLE = "ç©ºé—²"
    RUNNING = "è¿è¡Œä¸­"
    PAUSED = "å·²æš‚åœ"
    FINISHED = "å·²å®Œæˆ"


# ------------------------------------------------------------
# è¯»å–ç¯å¢ƒå˜é‡
# ------------------------------------------------------------


def _get_max_rounds() -> int:
    try:
        return int(os.environ.get("MAX_ROUNDS", 6))
    except Exception:
        return 6


# ------------------------------------------------------------
# å®Œæ•´çš„ LoopState å®ç°
# ------------------------------------------------------------


class CompleteLoopState(LoopState):
    """å®Œæ•´çš„å¾ªç¯çŠ¶æ€ï¼ˆå«è®¡æ—¶å™¨å®ç°ï¼‰"""

    def __init__(self):
        super().__init__()
        self._app_status = AppStatus.IDLE

    @property
    def status(self) -> AppStatus:
        return self._app_status

    @status.setter
    def status(self, value: AppStatus) -> None:
        self._app_status = value

    def get_elapsed_time(self) -> str:
        """è·å–å·²è¿è¡Œæ—¶é—´ï¼ˆæ ¼å¼åŒ–ï¼‰"""
        if not self.start_time:
            return "00:00"
        elapsed = time.time() - self.start_time
        return format_time(elapsed)

    def get_round_elapsed(self) -> str:
        """è·å–å½“å‰è½®æ¬¡å·²è¿è¡Œæ—¶é—´ï¼ˆæ ¼å¼åŒ–ï¼‰"""
        if not self.round_start_time:
            return "00:00"
        elapsed = time.time() - self.round_start_time
        return format_time(elapsed)

    def start_timer(self) -> None:
        """å¯åŠ¨ä¼šè¯è®¡æ—¶å™¨"""
        if not self.start_time:
            self.start_time = time.time()
        self.round_start_time = time.time()

    def start_round(self) -> None:
        """å¼€å§‹æ–°è½®æ¬¡è®¡æ—¶"""
        self.round_start_time = time.time()


def validate_judge(obj: Dict[str, Any]) -> Dict[str, Any]:
    obj.setdefault("done", False)
    obj.setdefault("summary", "æ— æ‘˜è¦")
    obj.setdefault("next_prompt", "ç»§ç»­")
    if obj["done"]:
        obj["next_prompt"] = ""
    return obj


# ------------------------------------------------------------
# Claude Code æ‰§è¡Œ
# ------------------------------------------------------------


def _refresh_ui():
    """åˆ·æ–° UIï¼ˆå ä½å®ç°ï¼Œå®é™…ç”±ä¸»ç¨‹åºæ³¨å…¥ï¼‰"""
    pass


def _handle_event(obj: Dict[str, Any], state: CompleteLoopState) -> None:
    """å¤„ç† Claude Code äº‹ä»¶"""
    etype = obj.get("type")

    if "usage" in obj:
        state.update_tokens(obj["usage"])
        _refresh_ui()

    if "session_id" in obj:
        sid = obj["session_id"]
        if sid and sid != state.session_id:
            state.session_id = sid

    if etype == "system":
        subtype = obj.get("subtype")
        if subtype == "init":
            cwd0 = obj.get("cwd")
            aprint(f"\033[90m[INIT] cwd={cwd0}\033[0m\n", end="")
        return

    if etype == "result":
        res = obj.get("result")
        if isinstance(res, str) and res:
            aprint(res, end="")
        else:
            aprint(json.dumps(obj, ensure_ascii=False, indent=2))
        return

    msg = obj.get("message") if isinstance(obj.get("message"), dict) else None
    if not msg:
        if "message" in obj and isinstance(obj["message"], dict) and "usage" in obj["message"]:
            state.update_tokens(obj["message"]["usage"])
            _refresh_ui()
        return

    if "usage" in msg:
        state.update_tokens(msg["usage"])
        _refresh_ui()

    from token_stats import extract_usage_from_obj, calc_tokens_for_usage

    content = msg.get("content")
    if not isinstance(content, list):
        if content:
            aprint(json.dumps(content, ensure_ascii=False, indent=2))
        return

    for block in content:
        if not isinstance(block, dict):
            continue
        btype = block.get("type")

        if btype == "text":
            text = block.get("text", "")
            if text:
                aprint(text, end="")
        elif btype == "thinking":
            thinking = block.get("thinking", "")
            if thinking:
                aprint(f"\033[90m[Thinking] {thinking}\033[0m\n", end="")
        elif btype == "tool_use":
            name = block.get("name", "")
            tin = block.get("input", {})
            display_content = json.dumps(tin, ensure_ascii=False, indent=2)
            if name == "Bash" and isinstance(tin, dict) and "command" in tin:
                display_content = f"$ {tin['command']}"
                if "description" in tin:
                    display_content += f"\n# {tin['description']}"
            _print_box(f"TOOL USE: {name}", display_content, style="tool_use")
        elif btype == "tool_result":
            tr_content = block.get("content", "")
            display_content = json.dumps(tr_content, ensure_ascii=False, indent=2)
            _print_box("TOOL RESULT", display_content, style="tool_result")

    if "tool_use_result" in obj:
        tur = obj["tool_use_result"]
        if isinstance(tur, dict):
            out = tur.get("stdout", "")
            err = tur.get("stderr", "")
            combined = ""
            if out:
                combined += out
            if err:
                combined += f"\n[STDERR]\n{err}"
            if combined.strip():
                _print_box("TOOL OUTPUT (STDOUT)", combined, style="tool_result")


async def run_claude_once(
    *, prompt: str, cwd: str = ".", state: CompleteLoopState
) -> tuple[str, TokenStats]:
    """è¿è¡Œä¸€æ¬¡ Claude Codeï¼Œè¿”å›è¾“å‡ºå’Œ Token ç»Ÿè®¡"""
    from json_utils import JSONBuffer, clean_invalid_unicode, detect_and_decode
    from token_stats import (
        calc_tokens_for_usage,
        extract_message_stats,
        TokenStats,
    )

    cli_args_str = os.environ.get("CLAUDE_CLI_ARGS", "--print --verbose --output-format stream-json")
    args = ["claude"] + shlex.split(cli_args_str)
    args.append(prompt)

    aprint(f"\n\033[1;35m>>> è°ƒç”¨ Claude Code (cwd: {cwd}) ...\033[0m\n", end="")

    proc = await asyncio.create_subprocess_exec(
        *args,
        cwd=cwd,
        env=os.environ.copy(),
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.STDOUT,
    )

    json_buffer = JSONBuffer()
    raw_chunks: List[str] = []
    captured_tool_outputs: List[str] = []
    round_tokens = TokenStats()

    def _update_message_stats(obj: Dict[str, Any]) -> None:
        """æ›´æ–°æ¶ˆæ¯ç»Ÿè®¡"""
        nonlocal round_tokens
        msg_stats = extract_message_stats(obj)
        if msg_stats["has_usage"]:
            usage = obj.get("message", {}).get("usage") or obj.get("usage")
            if usage:
                token_info = calc_tokens_for_usage(usage)
                round_tokens.input_tokens = token_info["input_tokens"]
                round_tokens.output_tokens = token_info["output_tokens"]
                round_tokens.cache_creation_tokens = token_info["cache_creation_tokens"]
                round_tokens.cache_read_tokens = token_info["cache_read_tokens"]

        role = msg_stats.get("role")
        if role == "user":
            round_tokens.user_text_tokens += msg_stats["text_length"]
        elif role == "assistant":
            round_tokens.assistant_text_tokens += msg_stats["text_length"]
            round_tokens.tool_use_tokens += msg_stats["tool_use_count"] * 50
            round_tokens.tool_result_tokens += msg_stats["tool_result_count"] * 30

    def _maybe_capture_tool_output(obj: Dict[str, Any], outputs: List[str]) -> None:
        """æ•è·å·¥å…·è¾“å‡ºç”¨äºæ—¥å¿—è®°å½•"""
        if "tool_use_result" in obj:
            tur = obj["tool_use_result"]
            if isinstance(tur, dict):
                out = tur.get("stdout", "")
                err = tur.get("stderr", "")
                if out:
                    outputs.append(f"[STDOUT]\n{out}")
                if err:
                    outputs.append(f"[STDERR]\n{err}")

        msg = obj.get("message")
        if isinstance(msg, dict):
            content = msg.get("content")
            if isinstance(content, list):
                for block in content:
                    if isinstance(block, dict) and block.get("type") == "tool_result":
                        tr_content = block.get("content", "")
                        if isinstance(tr_content, str) and tr_content.strip():
                            outputs.append(f"[TOOL RESULT]\n{tr_content}")

    try:
        assert proc.stdout is not None
        while True:
            data = await proc.stdout.read(4096)
            if not data:
                break

            s = detect_and_decode(data)
            s = clean_invalid_unicode(s)
            raw_chunks.append(s)

            objects = json_buffer.feed(s)
            for obj in objects:
                if isinstance(obj, dict):
                    _update_message_stats(obj)
                    _maybe_capture_tool_output(obj, captured_tool_outputs)
                    _handle_event(obj, state)

        if json_buffer.has_data():
            objects = json_buffer.feed("")
            for obj in objects:
                if isinstance(obj, dict):
                    _update_message_stats(obj)
                    _maybe_capture_tool_output(obj, captured_tool_outputs)
                    _handle_event(obj, state)

        await proc.wait()

    except asyncio.CancelledError:
        aprint("\n\033[33m[System] æ­£åœ¨åœæ­¢ Claude è¿›ç¨‹...\033[0m")
        try:
            proc.terminate()
            await asyncio.wait_for(proc.wait(), timeout=2.0)
        except Exception:
            try:
                proc.kill()
            except Exception:
                pass
        raise

    all_output = "".join(raw_chunks).strip()
    if captured_tool_outputs:
        captured = "\n".join(captured_tool_outputs)
        all_output = f"{all_output}\n{captured}".strip()

    return clean_invalid_unicode(all_output), round_tokens


# ------------------------------------------------------------
# Judge & Controller
# ------------------------------------------------------------


def _get_openai_client():
    """è·å– OpenAI client"""
    import pathlib

    # åªä»è„šæœ¬ç›®å½•åŠ è½½ .env æ–‡ä»¶
    env_path = pathlib.Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)

    from openai import OpenAI
    return OpenAI(
        api_key=os.environ["OPENAI_API_KEY"],
        base_url=os.environ["OPENAI_BASE_URL"],
    )


def judge_once(
    *, goal: str, claude_output: str, memory: List[Dict[str, Any]], state: CompleteLoopState
) -> Dict[str, Any]:
    """è¯·æ±‚ Judge åˆ¤å®š"""
    from json_utils import extract_first_json

    if not os.environ.get("OPENAI_API_KEY"):
        return {"done": False, "summary": "æ— Key", "next_prompt": "ç»§ç»­"}

    model = os.environ.get("OPENAI_MODEL", "gpt-4")

    aprint(f"\n\033[1;34m>>> æ­£åœ¨è¯·æ±‚ Judge ({model}) ...\033[0m")

    try:
        client = _get_openai_client()

        judge_input = claude_output
        if len(judge_input) > 6000:
            judge_input = judge_input[:2000] + "\n...[truncated]...\n" + judge_input[-4000:]

        payload = {"goal": goal, "claude_output": judge_input, "memory": memory}

        resp = client.chat.completions.create(
            model=model,
            temperature=0,
            messages=[
                {"role": "system", "content": JUDGE_SYSTEM},
                {"role": "user", "content": json.dumps(payload, ensure_ascii=False)},
            ],
        )

        if hasattr(resp, "usage") and resp.usage:
            state.update_tokens(resp.usage)
            _refresh_ui()

        text = resp.choices[0].message.content or ""
        text = clean_invalid_unicode(text)
        aprint(f"\033[90m[Judge Output]\n{text}\033[0m\n")

        return validate_judge(extract_first_json(text))

    except Exception as e:
        aprint(f"\033[31m[Judge Error] {e}\033[0m")
        return {"done": False, "summary": f"Judgeå‡ºé”™: {e}", "next_prompt": "ç»§ç»­"}


def refine_goal_once(*, goal: str, state: CompleteLoopState) -> str:
    """æ¶¦è‰²ç›®æ ‡"""
    from json_utils import clean_invalid_unicode
    import pathlib

    # ç¡®ä¿åŠ è½½ .env
    env_path = pathlib.Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)

    if not os.environ.get("OPENAI_API_KEY"):
        return goal

    model = os.environ.get("OPENAI_MODEL", "gpt-4")

    try:
        client = _get_openai_client()

        resp = client.chat.completions.create(
            model=model,
            temperature=0,
            messages=[
                {"role": "system", "content": REFINE_SYSTEM},
                {"role": "user", "content": goal},
            ],
        )

        if hasattr(resp, "usage") and resp.usage:
            state.update_tokens(resp.usage)
            _refresh_ui()

        refined = resp.choices[0].message.content or ""
        refined = clean_invalid_unicode(refined).strip()
        return refined if refined else goal

    except Exception as e:
        aprint(f"\033[31m[Refine Error] {e}\033[0m")
        return goal


def summarize_goal_once(*, goal: str, state: CompleteLoopState) -> str:
    """ç”Ÿæˆç²¾ç®€ç‰ˆç›®æ ‡"""
    import pathlib

    # ç¡®ä¿åŠ è½½ .env
    env_path = pathlib.Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)

    if not os.environ.get("OPENAI_API_KEY"):
        return goal

    model = os.environ.get("OPENAI_MODEL", "gpt-4")

    try:
        client = _get_openai_client()

        resp = client.chat.completions.create(
            model=model,
            temperature=0,
            messages=[
                {"role": "system", "content": SUMMARIZE_SYSTEM},
                {"role": "user", "content": goal},
            ],
        )

        if hasattr(resp, "usage") and resp.usage:
            state.update_tokens(resp.usage)
            _refresh_ui()

        summary = resp.choices[0].message.content.strip()
        return summary if summary else goal

    except Exception:
        return goal


def update_goal_once(
    *, original_goal: str, additional_instruction: str, state: CompleteLoopState
) -> str:
    """æ›´æ–°ç›®æ ‡"""
    import pathlib

    # ç¡®ä¿åŠ è½½ .env
    env_path = pathlib.Path(__file__).parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)

    if not os.environ.get("OPENAI_API_KEY"):
        return original_goal

    model = os.environ.get("OPENAI_MODEL", "gpt-4")
    aprint(f"\n\033[1;34m>>> æ­£åœ¨è¯·æ±‚ Goal Updater ({model}) ...\033[0m")

    try:
        client = _get_openai_client()

        prompt = f"åŸç›®æ ‡ï¼š{original_goal}\n\nè¿½åŠ æŒ‡ä»¤ï¼š{additional_instruction}\n\nè¯·ç»“åˆè¿½åŠ æŒ‡ä»¤ï¼Œé‡æ–°è¡¨è¿°ä¸€ä¸ªæ–°çš„ç›®æ ‡ã€‚ä¿æŒç®€æ´æ˜äº†ã€‚"

        resp = client.chat.completions.create(
            model=model,
            temperature=0.7,
            messages=[
                {"role": "system", "content": GOAL_UPDATER_SYSTEM},
                {"role": "user", "content": prompt},
            ],
        )

        if hasattr(resp, "usage") and resp.usage:
            state.update_tokens(resp.usage)
            _refresh_ui()

        new_goal = resp.choices[0].message.content.strip()
        aprint(f"\033[90m[New Goal]\n{new_goal}\033[0m\n")
        return new_goal

    except Exception as e:
        aprint(f"\033[31m[Goal Update Error] {e}\033[0m")
        return original_goal


def build_claude_prompt(goal: str, refined_goal: str, next_instruction: str, is_first: bool) -> str:
    """æ„å»ºå‘é€ç»™ Claude çš„æç¤º"""
    display_goal = refined_goal if is_first and refined_goal else goal
    if next_instruction.strip():
        return f"ç›®æ ‡ï¼š{display_goal}\n\nä¸Šä¸€è½®è¿›å±•æ‘˜è¦ï¼š{next_instruction}\n\nè¯·ç»§ç»­å®Œæˆç›®æ ‡ã€‚"
    return f"ç›®æ ‡ï¼š{display_goal}\n\nè¯·å®Œæˆç›®æ ‡ã€‚"


async def self_loop(
    *, max_rounds: int = 6, cwd: str = ".", state: CompleteLoopState
) -> Dict[str, Any]:
    """è‡ªå¾ªç¯æ‰§è¡Œ"""
    next_instruction = ""
    if state.memory:
        last_mem = state.memory[-1]
        if not last_mem.get("done", False):
            next_instruction = last_mem.get("next_prompt", "")

    start_round = len(state.logs) + 1
    state.status = AppStatus.RUNNING
    state.start_timer()
    _refresh_ui()

    try:
        for r in range(start_round, start_round + max_rounds):
            state.current_round = r
            state.start_round()
            _refresh_ui()

            aprint(f"\n{'='*20} ROUND {r} {'='*20}")

            is_first = len(state.logs) == 0
            prompt = build_claude_prompt(state.goal, state.refined_goal, next_instruction, is_first)

            claude_output, round_tokens = await run_claude_once(prompt=prompt, cwd=cwd, state=state)
            round_tokens.round = r

            state.add_round_tokens(round_tokens)
            _refresh_ui()

            aprint(f"\033[90m[Token] è¾“å…¥: {round_tokens.input_tokens} | è¾“å‡º: {round_tokens.output_tokens} | "
                   f"ç¼“å­˜åˆ›å»º: {round_tokens.cache_creation_tokens} | ç¼“å­˜è¯»å–: {round_tokens.cache_read_tokens}\033[0m")

            judge = judge_once(goal=state.goal, claude_output=claude_output, memory=state.memory, state=state)

            aprint(f"ğŸ‘‰ \033[1mJudge åˆ¤å®š:\033[0m Done={judge['done']}")
            if judge.get("summary"):
                aprint(f"   æ‘˜è¦: {judge['summary']}")
            if not judge["done"] and judge.get("next_prompt"):
                aprint(f"   æŒ‡ç¤º: {judge['next_prompt']}")

            state.logs.append(RoundLog(r, prompt, claude_output, judge, tokens=round_tokens))
            state.memory.append({"round": r, "summary": judge["summary"], "next_prompt": judge["next_prompt"]})

            if judge["done"]:
                state.status = AppStatus.FINISHED
                state.goal_set = False
                # ä¿å­˜æœ€ç»ˆæ—¶é—´ï¼Œé˜²æ­¢åç»­é”®ç›˜è¾“å…¥åˆ·æ–°è®¡æ—¶
                state.final_elapsed = state.get_elapsed_time()
                _refresh_ui()
                return {"status": "completed", "rounds": r, "summary": judge["summary"]}

            next_instruction = judge["next_prompt"]

        state.status = AppStatus.PAUSED
        # ä¿å­˜æœ€ç»ˆæ—¶é—´ï¼Œé˜²æ­¢åç»­é”®ç›˜è¾“å…¥åˆ·æ–°è®¡æ—¶
        state.final_elapsed = state.get_elapsed_time()
        _refresh_ui()
        return {"status": "max_rounds_reached", "rounds": max_rounds, "summary": "è¾¾åˆ°è½®æ¬¡é™åˆ¶ï¼Œç­‰å¾…æŒ‡ç¤ºã€‚"}

    except asyncio.CancelledError:
        state.status = AppStatus.PAUSED
        _refresh_ui()
        raise
    except Exception as e:
        state.status = AppStatus.PAUSED
        _refresh_ui()
        aprint(f"\n[Error] Loop exception: {e}")
        return {"status": "error", "summary": str(e)}
